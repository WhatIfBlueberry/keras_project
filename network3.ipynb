{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91796394-6eec-4718-bf93-0a67b2fac039",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras import layers\n",
    "from tensorflow import data as tf_data\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60090d2e-bc71-4f81-adad-0fa0e157e9cb",
   "metadata": {},
   "source": [
    "## import and classify images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e953c8-0588-4cee-9187-b3074c30c6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = (120, 180)\n",
    "\n",
    "train_ds, val_ds = keras.utils.image_dataset_from_directory(\n",
    "    \"data\",\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"categorical\",\n",
    "    validation_split=0.2,\n",
    "    subset=\"both\",\n",
    "    seed=42,\n",
    "    image_size=image_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0348203-3bbc-44ca-826a-0cbe70c67b25",
   "metadata": {},
   "source": [
    "## show sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9cc939-835f-48a3-a009-1642282a90ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in train_ds.take(1):\n",
    "    for i in range(9):\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(np.array(images[i]).astype(\"uint8\"))\n",
    "        plt.title(int(labels[i]))\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "320b5ad8-ca60-483d-9998-8df5ab7017fd",
   "metadata": {},
   "source": [
    "## data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03134ec2-ebfb-4ba1-ac0f-e363e57374ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation_layers = [\n",
    "    layers.RandomFlip(\"horizontal\"),\n",
    "    layers.RandomRotation(0.1),\n",
    "]\n",
    "\n",
    "\n",
    "def data_augmentation(images):\n",
    "    for layer in data_augmentation_layers:\n",
    "        images = layer(images)\n",
    "    return images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21a1a25-f9ab-439c-8218-ba77b43ee9ba",
   "metadata": {},
   "source": [
    "## make augmentation go brrr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb96d48-5bfb-49b3-87e0-b8cf2b37b763",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply `data_augmentation` to the training images.\n",
    "train_ds = train_ds.map(\n",
    "    lambda img, label: (data_augmentation(img), label),\n",
    "    num_parallel_calls=tf_data.AUTOTUNE,\n",
    ")\n",
    "# Prefetching samples in GPU memory helps maximize GPU utilization.\n",
    "train_ds = train_ds.prefetch(tf_data.AUTOTUNE)\n",
    "val_ds = val_ds.prefetch(tf_data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab785cb1-eca6-4af6-847e-6be84632b0c0",
   "metadata": {},
   "source": [
    "## build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e02d22-d483-479c-a922-28e6216e6077",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(input_shape, num_classes):\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "\n",
    "    # Entry block\n",
    "    x = layers.Rescaling(1.0 / 255)(inputs)\n",
    "    x = layers.Conv2D(128, 3, strides=2, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "\n",
    "    previous_block_activation = x  # Set aside residual\n",
    "\n",
    "    for size in [256, 512, 728]:\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "        x = layers.SeparableConv2D(size, 3, padding=\"same\")(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "        x = layers.SeparableConv2D(size, 3, padding=\"same\")(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        x = layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n",
    "\n",
    "        # Project residual\n",
    "        residual = layers.Conv2D(size, 1, strides=2, padding=\"same\")(\n",
    "            previous_block_activation\n",
    "        )\n",
    "        x = layers.add([x, residual])  # Add back residual\n",
    "        previous_block_activation = x  # Set aside next residual\n",
    "\n",
    "    x = layers.SeparableConv2D(1024, 3, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dropout(0.25)(x)\n",
    "\n",
    "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "    return keras.Model(inputs, outputs)\n",
    "\n",
    "# + (3,) for the RGB color channels\n",
    "model = make_model(input_shape=image_size + (3,), num_classes=53)\n",
    "#keras.utils.plot_model(model, show_shapes=True)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c17eb8-da3b-45e4-9342-5e749e6cc192",
   "metadata": {},
   "source": [
    "## train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb584065-9049-4f66-aa55-bca3ab3833c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 25\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\"save_at_{epoch}.keras\"),\n",
    "]\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(3e-4),\n",
    "    loss=keras.losses.CategoricalCrossentropy(),\n",
    "    metrics=[keras.metrics.CategoricalAccuracy(name=\"acc\")],\n",
    ")\n",
    "model.fit(\n",
    "    train_ds,\n",
    "    epochs=epochs,\n",
    "    callbacks=callbacks,\n",
    "    validation_data=val_ds,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff37e6b5-3beb-4133-ab28-8013d77d25d3",
   "metadata": {},
   "source": [
    "## validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd24cf9-8ad7-4a64-af5c-7e80a1b9f7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = keras.utils.load_img(\"PetImages/Cat/6779.jpg\", target_size=image_size)\n",
    "plt.imshow(img)\n",
    "\n",
    "img_array = keras.utils.img_to_array(img)\n",
    "img_array = keras.ops.expand_dims(img_array, 0)  # Create batch axis\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = float(keras.ops.sigmoid(predictions[0][0]))\n",
    "print(f\"This image is {100 * (1 - score):.2f}% cat and {100 * score:.2f}% dog.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
